{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: \n",
    "\n",
    "Everything written here about this application is based on personal knowledge gathered up to some arbitrary point of learning. \n",
    "\n",
    "Refer to original documentation instead of this when working on actual projects.\n",
    "\n",
    "Ref: https://kafka.apache.org/intro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Terms\n",
    "---------------\n",
    "\n",
    "Event Streaming: This simply boils down to the process of collecting, storing, processing and presenting real-time data from various sources. Event streaming thus allows us to ensure a continous flow (collection and storage) and interpretion(processing, presenting) of real-time data. \n",
    "\n",
    "Broker: So far brokers seems like storage servers. It is often indicated throughout the official documentation that Kafka is always as a 'cluster' of servers. The servers that form the storage layer, are called brokers. Naturally, I wondered why call these servers 'brokers'? It turned out that the name actually represents what these servers do. They act as a broker between 'Producers' and 'Consumers'.\n",
    "\n",
    "Kafka Topic: Analogically Topics are equivalent to what we would call a Table in a SQL database, or a Collection in a NoSQL database. A broker server stores data in a storage unit called a 'Kafka Topic'. This allows us to organize data sent to a broker using separate and meaningful names. \n",
    "\n",
    "Producer: These are basically various sources of data. They produce data that are mapped to various kafka topics stored inside a broker. \n",
    "\n",
    "Consumer: A consumer is an application that consumes specific data streams/kafka topics that are stored inside a broker. Kafka doesn't allow any direct transaction to occur between a producer and a consumer, and they must interact with each other through a broker(at least that's what I have seen up to now). This ensures a single point of data writing and reading, which seems to have many advantages.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
